{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from load_data import get_data\n",
    "\n",
    "# explicitly require this experimental feature\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "# now you can import normally from ensemble\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/ADA/load_data.py:34: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  alldf = pd.concat([train_df,test_df])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (24584, 63)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_pred, session_ids = get_data(is_fill=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1500 candidates, totalling 3000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed: 14.5min\n",
      "[Parallel(n_jobs=4)]: Done 640 tasks      | elapsed: 20.4min\n",
      "[Parallel(n_jobs=4)]: Done 874 tasks      | elapsed: 28.2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "min_impurity_split = [1e-5, 1e-6, 1e-7, 1e-8, 1e-9]\n",
    "param_grid = {\n",
    "              'max_iter': randint(10, 1000),\n",
    "              'max_depth': randint(2, 10),\n",
    "              'min_samples_leaf': randint(2, 40),\n",
    "             }\n",
    "clf = RandomizedSearchCV(HistGradientBoostingClassifier(),\n",
    "                   scoring='roc_auc',\n",
    "                   param_distributions=param_grid, cv=2, n_jobs=4, n_iter=1500,\n",
    "                   verbose=5)\n",
    "clf.fit(x_train.to_numpy(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = clf.cv_results_['mean_test_score'].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8848658987005172"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_['mean_test_score'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter=60, max_depth=7, min_samples_leaf=37\n"
     ]
    }
   ],
   "source": [
    "print(f\"max_iter={clf.cv_results_['param_max_iter'][i]}, max_depth={clf.cv_results_['param_max_depth'][i]}, min_samples_leaf={clf.cv_results_['param_min_samples_leaf'][i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid = {'l2_regularization':[10],'max_iter': [50, 100, 200, 300]}\n",
    "clf = GridSearchCV(HistGradientBoostingClassifier(),\n",
    "                   scoring='roc_auc',\n",
    "                   param_grid=param_grid, cv=2, n_jobs=8,\n",
    "                   verbose=5, return_train_score=True)\n",
    "clf.fit(x_train.to_numpy(), y_train.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(clf.cv_results_['mean_test_score'])\n",
    "plt.plot(clf.cv_results_['mean_train_score'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
